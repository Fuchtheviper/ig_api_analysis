# ğŸ“· Instagram ETL Data Pipeline
ğŸš€ **An end-to-end data pipeline for extracting, analyzing, and storing Instagram hashtag data using Airflow, MongoDB, and DeepSeek API.**

## ğŸ“Œ Project Overview
This project automates **data extraction, sentiment analysis, and topic classification** from Instagram hashtags. It is **built on Airflow** and **designed for scalability** using **Docker & MongoDB**.

### ğŸ¯ Key Features
âœ… **Fully Automated Workflow** â†’ Uses **Airflow** to schedule & process Instagram data.  
âœ… **Efficient Storage Handling** â†’ Uses **temporary JSON storage** to optimize data transfer.  
âœ… **Sentiment Analysis** â†’ Uses **OpenAI GPT API** to classify posts as **Positive, Neutral, or Negative**.  
âœ… **Topic Classification** â†’ Uses **DeepSeek API** to categorize post topics dynamically.  
âœ… **Scalable & Modular** â†’ Can be expanded to **analyze multiple social media sources**.

## ğŸ“Œ How It Works

This pipeline follows the **ETL (Extract, Transform, Load) workflow**:

1ï¸âƒ£ **Extract**: Fetches Instagram hashtag data from the API.  
2ï¸âƒ£ **Transform**: Cleans data, analyzes sentiment, and classifies topics.  
3ï¸âƒ£ **Load**: Saves processed data to MongoDB for further analysis.

## Setup & Installation
Remark : Install Airflow, MongoDB and Docker on your own
Install Dependencies
- pip install -r requirements.txt
Start the Infrastructure (Airflow & MongoDB)
- docker-compose up -d --build

## Access Airflow UI
- URL: http://localhost:8080
- Username: admin
- Password: "Check in airflow-tainer volumn in docker"

## Run the DAG
- Go to DAGs â†’ instagram_etl_pipeline
- Click "Trigger DAG"
- Monitor DAG execution

## Verify Processed Data in MongoDB
Option 1 Using Mongo Shell
- docker exec -it mongodb-container mongosh
- use instagram_data
- db.posts.find().pretty()

Option 2 Using MongoDB Compass
- Connect to MongoDB  URI: mongodb://localhost:27017/
- View the posts collection
